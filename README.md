<<<<<<< HEAD
# ðŸš€ NOVA API IA - DocumentaciÃ³n Completa

## Tabla de Contenidos

1. [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
2. [Requisitos del Sistema](#requisitos-del-sistema)
3. [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
4. [ConfiguraciÃ³n de Ollama e IA](#configuraciÃ³n-de-ollama-e-ia)
5. [Estructura del Proyecto](#estructura-del-proyecto)
6. [Endpoints de la API](#endpoints-de-la-api)
7. [Logs y Monitoreo](#logs-y-monitoreo)
8. [Ejecutar la API](#ejecutar-la-api)
9. [Pruebas de la API](#pruebas-de-la-api)
10. [SoluciÃ³n de Problemas](#soluciÃ³n-de-problemas)

---

## DescripciÃ³n del Proyecto

**NOVA API IA** es una API REST construida con **Flask** que proporciona acceso a modelos de inteligencia artificial locales mediante **Ollama**. Esta API permite que la aplicaciÃ³n NOVA realice consultas a modelos de IA sin depender de servicios en la nube.

### CaracterÃ­sticas Principales:
- âœ… API REST con endpoints simples y claros
- âœ… IntegraciÃ³n con Ollama (ejecuciÃ³n local de modelos IA)
- âœ… Modelo Qwen 2.5 0.5B (ligero y rÃ¡pido)
- âœ… Sistema completo de logs y monitoreo
- âœ… CORS habilitado para compatibilidad multi-origen
- âœ… Health check automÃ¡tico
- âœ… Manejo robusto de errores

---

## Requisitos del Sistema

### Software Requerido:
- **Python** 3.8 o superior
- **Ollama** (para ejecutar modelos de IA)
- **pip** (gestor de paquetes de Python)
- Windows PowerShell o CMD

### Requisitos MÃ­nimos de Hardware:
- Procesador: Intel i5 / AMD Ryzen 5 o superior
- RAM: 4 GB mÃ­nimo, 8 GB recomendado
- Almacenamiento: 5 GB libres (para modelos)
- ConexiÃ³n a Internet (solo para descargas iniciales)

---

## InstalaciÃ³n y ConfiguraciÃ³n

### Paso 1: Clonar o Descargar el Proyecto

```powershell
# Navegar a la carpeta del proyecto
cd C:\xampp\htdocs\NOVA_ASISTENTE\API_IA
```

### Paso 2: Crear Entorno Virtual

```powershell
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
.\venv\Scripts\activate

# Verificar que estÃ© activado (deberÃ¡ mostrar (venv) en el prompt)
```

### Paso 3: Instalar Dependencias

```powershell
# Instalar las dependencias del proyecto
pip install -r requirements.txt

# Las dependencias instaladas son:
# - flask: Framework web
# - flask-cors: Soporte CORS
# - requests: Cliente HTTP
# - sseclient-py: Soporte para Server-Sent Events
```

### Paso 4: Verificar InstalaciÃ³n

```powershell
# Verificar que Python tiene las dependencias correctas
pip list

# DeberÃ¡ mostrar todas las librerÃ­as instaladas con sus versiones
```

---

## ConfiguraciÃ³n de Ollama e IA

### Paso 1: Descargar e Instalar Ollama

1. **Descargar Ollama:**
   - Ir a https://ollama.ai
   - Descargar la versiÃ³n para Windows
   - Ejecutar el instalador y seguir las instrucciones

2. **Verificar la instalaciÃ³n:**
   ```powershell
   # En una terminal nueva (sin venv activado)
   ollama --version
   ```

### Paso 2: Descargar el Modelo Qwen 2.5 0.5B

El modelo utilizado es **Qwen 2.5 0.5B**, optimizado para ser ligero y rÃ¡pido.

```powershell
# En una terminal nueva (sin venv activado o en otra ventana)
ollama pull qwen2.5:0.5b

# Esto descargarÃ¡ el modelo (~300-400 MB)
# Tiempo estimado: 2-5 minutos (depende de tu conexiÃ³n)
```

### Paso 3: Verificar que el Modelo estÃ¡ Descargado

```powershell
# Listar modelos disponibles
ollama list

# DeberÃ¡ mostrar: qwen2.5:0.5b
```

### Paso 4: Iniciar Ollama en Modo Servidor

Antes de ejecutar la API, necesitas tener Ollama corriendo como servidor:

```powershell
# En una terminal nueva
ollama serve

# Salida esperada:
# 2025-11-21T10:30:00.000000Z INFO [llm] starting up the LLM...
# 2025-11-21T10:30:05.000000Z INFO [llm] loaded model qwen2.5:0.5b
# Listening on 127.0.0.1:11434
```

**Nota:** MantÃ©n esta terminal abierta mientras ejecutas la API.

### Paso 5: Prueba RÃ¡pida de Ollama

```powershell
# En otra terminal, puedes probar Ollama directamente
ollama run qwen2.5:0.5b "Hola, Â¿quiÃ©n eres?"

# El modelo responderÃ¡ con un saludo
```

---

## Estructura del Proyecto

```
C:\xampp\htdocs\NOVA_ASISTENTE\API_IA\
â”‚
â”œâ”€â”€ api_ia.py              # Archivo principal de la API
â”œâ”€â”€ requirements.txt       # Dependencias del proyecto
â”œâ”€â”€ README.md             # Esta documentaciÃ³n
â”‚
â”œâ”€â”€ venv/                 # Entorno virtual (creado automÃ¡ticamente)
â”‚   â”œâ”€â”€ Scripts/
â”‚   â”‚   â”œâ”€â”€ activate      # Script para activar venv
â”‚   â”‚   â”œâ”€â”€ python.exe
â”‚   â”‚   â””â”€â”€ pip.exe
â”‚   â””â”€â”€ Lib/
â”‚
â””â”€â”€ logs/                 # Carpeta de logs (creada automÃ¡ticamente)
    â””â”€â”€ api_nova.log      # Archivo de registro de eventos
```

### DescripciÃ³n de Archivos:

| Archivo | DescripciÃ³n |
|---------|-------------|
| `api_ia.py` | CÃ³digo principal de la API Flask con todos los endpoints |
| `requirements.txt` | Lista de dependencias Python necesarias |
| `README.md` | DocumentaciÃ³n del proyecto (este archivo) |
| `venv/` | Entorno virtual aislado con todas las dependencias |
| `logs/api_nova.log` | Registro de todas las operaciones, errores y eventos |

---

## Endpoints de la API

### 1. **GET /status** - Health Check

Verifica si la API estÃ¡ funcionando correctamente.

**URL:** `http://localhost:5002/status`

**MÃ©todo:** `GET`

**Respuesta Exitosa (200):**
```json
{
  "status": "ok",
  "message": "API IA de NOVA funcionando correctamente ðŸš€"
}
```

**Uso:**
```powershell
# Desde PowerShell
Invoke-WebRequest -Uri "http://localhost:5002/status" -Method GET
```

---

### 2. **POST /chat** - Consulta a la IA

EnvÃ­a un prompt a la IA y recibe una respuesta.

**URL:** `http://localhost:5002/chat`

**MÃ©todo:** `POST`

**Headers:**
```
Content-Type: application/json
```

**Body (JSON):**
```json
{
  "prompt": "Tu pregunta o consulta aquÃ­"
}
```

**Respuesta Exitosa (200):**
```json
{
  "success": true,
  "model": "qwen2.5:0.5b",
  "response": "Respuesta de la IA aquÃ­"
}
```

**Respuesta con Error (400 o 500):**
```json
{
  "error": "DescripciÃ³n del error",
  "details": "InformaciÃ³n adicional del error"
}
```

**Ejemplos de Uso:**

```powershell
# Usando PowerShell
$body = @{
    prompt = "Â¿CuÃ¡l es la capital de Francia?"
} | ConvertTo-Json

Invoke-WebRequest -Uri "http://localhost:5002/chat" `
    -Method POST `
    -ContentType "application/json" `
    -Body $body
```

```bash
# Usando curl (en otra terminal/bash)
curl -X POST http://localhost:5002/chat \
  -H "Content-Type: application/json" \
  -d "{\"prompt\": \"Â¿CuÃ¡l es 2+2?\"}"
```

```python
# Usando Python
import requests

response = requests.post(
    "http://localhost:5002/chat",
    json={"prompt": "Explica quÃ© es la inteligencia artificial"}
)
print(response.json())
```

---

### 3. **GET /** - Home

Endpoint raÃ­z para verificar que la API estÃ¡ respondiendo.

**URL:** `http://localhost:5002/`

**MÃ©todo:** `GET`

**Respuesta:** `API IA de NOVA corriendo en Flask ðŸš€`

---

## Logs y Monitoreo

### UbicaciÃ³n del Archivo de Logs

```
C:\xampp\htdocs\NOVA_ASISTENTE\API_IA\logs\api_nova.log
```

### Tipos de Eventos Registrados

1. **INFO:** Solicitudes recibidas, respuestas exitosas
2. **ERROR:** Errores en la comunicaciÃ³n, excepciones, fallos

### Ejemplo de Contenido del Log

```
2025-11-21 10:30:15,123 [INFO] Prompt recibido: Â¿CuÃ¡l es tu nombre?
2025-11-21 10:30:18,456 [INFO] Respuesta del modelo: Mi nombre es Qwen...
2025-11-21 10:31:02,789 [ERROR] Error desde Ollama: Connection refused
```

### CÃ³mo Revisar los Logs

```powershell
# Ver Ãºltimas 50 lÃ­neas del log
Get-Content C:\xampp\htdocs\NOVA_ASISTENTE\API_IA\logs\api_nova.log -Tail 50

# Ver logs en tiempo real
Get-Content -Path C:\xampp\htdocs\NOVA_ASISTENTE\API_IA\logs\api_nova.log -Tail 10 -Wait

# Buscar errores en los logs
Select-String "ERROR" C:\xampp\htdocs\NOVA_ASISTENTE\API_IA\logs\api_nova.log
```

---

## Ejecutar la API

### OpciÃ³n 1: EjecuciÃ³n Manual Paso a Paso

**Terminal 1 - Iniciar Ollama:**
```powershell
# Sin activar venv
ollama serve
```

**Terminal 2 - Iniciar API Flask:**
```powershell
# Navegar al proyecto
cd C:\xampp\htdocs\NOVA_ASISTENTE\API_IA

# Activar entorno virtual
.\venv\Scripts\activate

# Ejecutar la API
python api_ia.py

# Salida esperada:
# * Serving Flask app 'api_ia'
# * Debug mode: on
# * Running on http://0.0.0.0:5002
```

### OpciÃ³n 2: Script de EjecuciÃ³n AutomÃ¡tica

Crea un archivo `run.ps1`:

```powershell
# Iniciar Ollama (en background)
Start-Process -FilePath "ollama" -ArgumentList "serve"

# Esperar a que Ollama estÃ© listo
Start-Sleep -Seconds 3

# Navegar a la carpeta del proyecto
cd C:\xampp\htdocs\NOVA_ASISTENTE\API_IA

# Activar venv
.\venv\Scripts\activate

# Ejecutar API
python api_ia.py
```

Para ejecutar: `.\run.ps1`

---

## Pruebas de la API

### Prueba 1: Verificar ConexiÃ³n

```powershell
# Abrir PowerShell y ejecutar:
Invoke-WebRequest -Uri "http://localhost:5002/status" -Method GET | ConvertTo-Json
```

**Resultado Esperado:**
```
{
  "status": "ok",
  "message": "API IA de NOVA funcionando correctamente ðŸš€"
}
```

---

### Prueba 2: Consulta BÃ¡sica a la IA

```powershell
$body = @{
    prompt = "Â¿CuÃ¡l es la capital de EspaÃ±a?"
} | ConvertTo-Json

$response = Invoke-WebRequest -Uri "http://localhost:5002/chat" `
    -Method POST `
    -ContentType "application/json" `
    -Body $body

$response.Content | ConvertFrom-Json
```

**Resultado Esperado:**
```json
{
  "success": true,
  "model": "qwen2.5:0.5b",
  "response": "La capital de EspaÃ±a es Madrid..."
}
```

---

### Prueba 3: Prueba de Rendimiento

```powershell
# Script para medir tiempo de respuesta
$prompts = @(
    "Â¿QuÃ© es Python?",
    "CuÃ©ntame un chiste",
    "Â¿CuÃ¡l es 2+2?"
)

foreach ($prompt in $prompts) {
    $body = @{ prompt = $prompt } | ConvertTo-Json
    
    $start = Get-Date
    $response = Invoke-WebRequest -Uri "http://localhost:5002/chat" `
        -Method POST `
        -ContentType "application/json" `
        -Body $body
    $end = Get-Date
    
    $time = ($end - $start).TotalSeconds
    Write-Host "Prompt: $prompt | Tiempo: ${time}s"
}
```

---

## SoluciÃ³n de Problemas

### Problema 1: "Connection refused" al conectar con Ollama

**Causa:** Ollama no estÃ¡ ejecutÃ¡ndose

**SoluciÃ³n:**
```powershell
# Abrir una nueva terminal y ejecutar:
ollama serve

# Mantener esta terminal abierta
```

---

### Problema 2: Error "Module not found" al ejecutar la API

**Causa:** El entorno virtual no estÃ¡ activado o las dependencias no estÃ¡n instaladas

**SoluciÃ³n:**
```powershell
# Activar venv
.\venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar de nuevo
python api_ia.py
```

---

### Problema 3: Puerto 5002 ya estÃ¡ en uso

**Causa:** Otra aplicaciÃ³n estÃ¡ usando el puerto

**SoluciÃ³n:**

```powershell
# Encontrar proceso usando puerto 5002
netstat -ano | findstr :5002

# Matar el proceso (reemplazar PID por el nÃºmero encontrado)
taskkill /PID <PID> /F

# O cambiar puerto en api_ia.py (lÃ­nea 108)
# Cambiar: app.run(host="0.0.0.0", port=5003, debug=True)
```

---

### Problema 4: Modelo no encontrado "qwen2.5:0.5b"

**Causa:** El modelo no estÃ¡ descargado

**SoluciÃ³n:**
```powershell
# Descargar el modelo
ollama pull qwen2.5:0.5b

# Esperar a que termine la descarga
```

---

### Problema 5: API lenta o congelada

**Causa:** Ollama estÃ¡ procesando una solicitud grande o el hardware es insuficiente

**SoluciÃ³n:**
- Aumentar tiempo de espera en cliente
- Usar prompts mÃ¡s cortos
- Asegurar disponibilidad de RAM
- Revisar logs: `Get-Content C:\xampp\htdocs\NOVA_ASISTENTE\API_IA\logs\api_nova.log -Tail 50`

---

## InformaciÃ³n TÃ©cnica

### Dependencias del Proyecto

```
flask==3.0.0                    # Framework web
flask-cors==4.0.0               # Soporte CORS
requests==2.31.0                # Cliente HTTP
sseclient-py==1.7               # Server-Sent Events
```

### ConfiguraciÃ³n de la API

```python
# Host: 0.0.0.0 (Accesible desde cualquier interfaz)
# Puerto: 5002
# Debug Mode: Activado (desarrollo)
# Modelo IA: qwen2.5:0.5b
# URL Ollama: http://localhost:11434/api/generate
```

### Versiones Probadas

- Python: 3.10, 3.11
- Windows: 10, 11
- Ollama: v0.1.0+
- Flask: 3.0.0

---

## GuÃ­a RÃ¡pida de Referencia

```powershell
# ========== PRIMER INICIO ==========

# 1. Abrir Terminal 1 - Iniciar Ollama
ollama serve

# 2. Abrir Terminal 2 - Iniciar API
cd C:\xampp\htdocs\NOVA_ASISTENTE\API_IA
.\venv\Scripts\activate
python api_ia.py

# 3. Abrir Terminal 3 - Hacer pruebas
Invoke-WebRequest -Uri "http://localhost:5002/status" -Method GET

# ========== INICIOS POSTERIORES ==========

# Terminal 1: Ollama
ollama serve

# Terminal 2: API
cd C:\xampp\htdocs\NOVA_ASISTENTE\API_IA
.\venv\Scripts\activate
python api_ia.py

# ========== ACTUALIZAR DEPENDENCIAS ==========
.\venv\Scripts\activate
pip install -r requirements.txt --upgrade

# ========== VER LOGS ==========
Get-Content C:\xampp\htdocs\NOVA_ASISTENTE\API_IA\logs\api_nova.log -Tail 50
```

---

## Contacto y Soporte

Para problemas o preguntas sobre la API:
1. Revisar los logs: `logs/api_nova.log`
2. Verificar que Ollama estÃ¡ ejecutÃ¡ndose
3. Confirmar que el modelo estÃ¡ descargado: `ollama list`
4. Revisar la secciÃ³n "SoluciÃ³n de Problemas"

---

**Ãšltima actualizaciÃ³n:** Noviembre 21, 2025

âœ… DocumentaciÃ³n Completa - Proyecto NOVA API IA
=======
# API_IA_NOVA
PROYECTO  DE CASA INTELIGENTE UNIVERCIDAD
>>>>>>> 99533923c0a605f9c34a65e8aaedb3a7bf22f289
